name: CI - Airflow PoC

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  e2e-test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Docker Compose
        run: |
          sudo apt-get update
          sudo apt-get install -y docker-compose jq

      - name: Configure GCP and AWS credentials
        run: |
          mkdir -p ./keys
          # GCPサービスアカウントキーをファイルに保存
          echo "${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}" | jq '.' > ./keys/gcp-key.json
          # AWSキーを環境変数に登録
          echo "AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}" >> $GITHUB_ENV
          echo "AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}" >> $GITHUB_ENV
          echo "AWS_DEFAULT_REGION=${{ secrets.AWS_DEFAULT_REGION }}" >> $GITHUB_ENV

      - name: Start Airflow with Docker Compose
        run: |
          docker-compose up -d
          echo "⏳ Waiting for Airflow to start..."
          sleep 60

      - name: Trigger Airflow DAG
        run: |
          WEB_SERVER=$(docker ps --format "{{.Names}}" | grep airflow-webserver)
          echo "Triggering DAG in container: $WEB_SERVER"
          docker exec $WEB_SERVER airflow dags trigger -d industry_metrics_from_input
          sleep 60
          docker exec $WEB_SERVER airflow dags state industry_metrics_from_input $(date +%Y-%m-%d)

      - name: Run pytest (check output)
        run: |
          pip install pytest pandas
          pytest -v
