name: CI

on:
  push:
    branches:
      - main
  pull_request:

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Set up job
        run: echo "Starting CI job"

      - name: Checkout repository
        uses: actions/checkout@v4

      # GCP 認証
      - name: Set up GCP credentials
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_CREDENTIALS }}

      # AWS 認証
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Add swap to prevent OOM
        run: |
          sudo fallocate -l 4G /swapfile
          sudo chmod 600 /swapfile
          sudo mkswap /swapfile
          sudo swapon /swapfile
          free -h

      - name: Start Docker Compose
        run: docker compose -f docker-compose.yml up -d

      # 改良版: Webserver のヘルスチェック & ログ出力
      - name: Wait for Airflow webserver to be healthy
        run: |
          echo "Waiting for Airflow webserver..."
          timeout=600
          interval=10
          elapsed=0
          healthy=false
          while [ $elapsed -lt $timeout ]; do
            if curl -s http://localhost:8080/health | grep -q '"status":"healthy"'; then
              echo "✅ Airflow webserver is healthy"
              healthy=true
              break
            else
              echo "⏳ Webserver not ready yet... (elapsed: ${elapsed}s)"
              docker compose logs --tail=20 airflow-webserver
            fi
            sleep $interval
            elapsed=$((elapsed + interval))
          done
          if [ "$healthy" = false ]; then
            echo "❌ Airflow webserver did not become healthy in time"
            docker compose logs airflow-webserver
            exit 1
          fi

      - name: Test GCS connection
        run: |
          echo "Testing GCS connection..."
          gsutil ls gs://$GCS_BUCKET || exit 1

      - name: Test S3 connection
        run: |
          echo "Testing S3 connection..."
          aws s3 ls s3://$S3_BUCKET || exit 1

      - name: Test BigQuery connection
        run: |
          echo "Testing BigQuery connection..."
          bq query --use_legacy_sql=false "SELECT 1" || exit 1

      - name: Trigger DAG run
        run: |
          echo "Triggering Airflow DAG run..."
          curl -X POST "http://localhost:8080/api/v1/dags/industry_metrics_full_dag/dagRuns" \
            -H "Content-Type: application/json" \
            --user "airflow:airflow" \
            -d '{"conf": {}}'

      - name: Wait for DAG to finish
        run: |
          echo "Waiting for DAG to finish..."
          sleep 60

      - name: Run pytest
        run: pytest -v

      - name: Tear down
        if: always()
        run: docker compose down -v
