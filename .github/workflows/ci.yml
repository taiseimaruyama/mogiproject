name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/gcp_key.json
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      BIGQUERY_DATASET: ${{ secrets.BIGQUERY_DATASET }}
      GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      # ğŸ”‘ GCP èªè¨¼ã‚­ãƒ¼ã‚’ Secrets ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åŒ–
      - name: Set up GCP credentials
        run: |
          echo "${{ secrets.GCP_CREDENTIALS }}" > $GOOGLE_APPLICATION_CREDENTIALS

      # Swap å¯¾ç­–ï¼ˆAirflow ã®é‡ã•å¯¾ç­–ï¼‰
      - name: Add swap to prevent OOM
        run: |
          echo "Adding 10GB swap..."
          sudo fallocate -l 10G /swapfile
          sudo chmod 600 /swapfile
          sudo mkswap /swapfile
          sudo swapon /swapfile
          free -h

      - name: Start Docker Compose
        run: docker-compose -f docker-compose.yml up -d

      # Webserver ã®ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ & ãƒ­ã‚°è¿½å¾“
      - name: Wait for Airflow webserver to be healthy
        run: |
          echo "Waiting for Airflow webserver..."
          docker-compose logs -f airflow-webserver &
          LOGS_PID=$!
          timeout=600
          interval=10
          elapsed=0
          healthy=false
          while [ $elapsed -lt $timeout ]; do
            if curl -s http://localhost:8080/health | grep -q '"status":"healthy"'; then
              echo "âœ… Airflow webserver is healthy"
              healthy=true
              break
            else
              echo "â³ Webserver not ready yet..."
            fi
            sleep $interval
            elapsed=$((elapsed + interval))
          done
          kill $LOGS_PID || true
          if [ "$healthy" = false ]; then
            echo "âŒ Airflow webserver did not become healthy in time"
            docker-compose logs airflow-webserver
            exit 1
          fi

      # ğŸ” èªè¨¼ç¢ºèªã‚¹ãƒ†ãƒƒãƒ—
      - name: Test GCS connection
        run: |
          echo "Testing GCS..."
          gsutil ls gs://my-gcs-bucket-2025-demo

      - name: Test S3 connection
        run: |
          echo "Testing S3..."
          aws s3 ls s3://domoproject

      - name: Test BigQuery connection
        run: |
          echo "Testing BigQuery..."
          bq ls ${{ secrets.GCP_PROJECT_ID }}:${{ secrets.BIGQUERY_DATASET }}

      # DAG å®Ÿè¡Œ
      - name: Trigger DAG run
        run: docker-compose exec -T airflow-webserver airflow dags trigger industry_metrics_from_input

      - name: Wait for DAG to finish
        run: |
          echo "Waiting for DAG..."
          timeout=600
          interval=30
          elapsed=0
          finished=false
          while [ $elapsed -lt $timeout ]; do
            state=$(docker-compose exec -T airflow-webserver airflow dags state industry_metrics_from_input $(date +%Y-%m-%d) | tail -n 1 | awk '{print $2}')
            echo "Current state: $state"
            if [ "$state" = "success" ]; then
              echo "âœ… DAG succeeded"
              finished=true
              break
            fi
            sleep $interval
            elapsed=$((elapsed + interval))
          done
          if [ "$finished" = false ]; then
            echo "âŒ DAG did not finish in time"
            docker-compose logs airflow-webserver
            exit 1
          fi

      # Pytest å®Ÿè¡Œï¼ˆæˆæœç‰©ç¢ºèªï¼‰
      - name: Run pytest
        run: docker-compose exec -T airflow-webserver pytest /opt/airflow/tests

      # Tear down
      - name: Tear down
        if: always()
        run: docker-compose down -v
        
