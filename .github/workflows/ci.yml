name: CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/gcp_key.json
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      BIGQUERY_DATASET: ${{ secrets.BIGQUERY_DATASET }}
      GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      # 🔑 GCP 認証キーを Secrets からファイル化
      - name: Set up GCP credentials
        run: |
          echo "${{ secrets.GCP_CREDENTIALS }}" > $GOOGLE_APPLICATION_CREDENTIALS

      # Swap 対策（Airflow の重さ対策）
      - name: Add swap to prevent OOM
        run: |
          echo "Adding 10GB swap..."
          sudo fallocate -l 10G /swapfile
          sudo chmod 600 /swapfile
          sudo mkswap /swapfile
          sudo swapon /swapfile
          free -h

      - name: Start Docker Compose
        run: docker-compose -f docker-compose.yml up -d

      # Webserver のヘルスチェック & ログ追従
      - name: Wait for Airflow webserver to be healthy
        run: |
          echo "Waiting for Airflow webserver..."
          docker-compose logs -f airflow-webserver &
          LOGS_PID=$!
          timeout=600
          interval=10
          elapsed=0
          healthy=false
          while [ $elapsed -lt $timeout ]; do
            if curl -s http://localhost:8080/health | grep -q '"status":"healthy"'; then
              echo "✅ Airflow webserver is healthy"
              healthy=true
              break
            else
              echo "⏳ Webserver not ready yet..."
            fi
            sleep $interval
            elapsed=$((elapsed + interval))
          done
          kill $LOGS_PID || true
          if [ "$healthy" = false ]; then
            echo "❌ Airflow webserver did not become healthy in time"
            docker-compose logs airflow-webserver
            exit 1
          fi

      # 🔎 認証確認ステップ
      - name: Test GCS connection
        run: |
          echo "Testing GCS..."
          gsutil ls gs://my-gcs-bucket-2025-demo

      - name: Test S3 connection
        run: |
          echo "Testing S3..."
          aws s3 ls s3://domoproject

      - name: Test BigQuery connection
        run: |
          echo "Testing BigQuery..."
          bq ls ${{ secrets.GCP_PROJECT_ID }}:${{ secrets.BIGQUERY_DATASET }}

      # DAG 実行
      - name: Trigger DAG run
        run: docker-compose exec -T airflow-webserver airflow dags trigger industry_metrics_from_input

      - name: Wait for DAG to finish
        run: |
          echo "Waiting for DAG..."
          timeout=600
          interval=30
          elapsed=0
          finished=false
          while [ $elapsed -lt $timeout ]; do
            state=$(docker-compose exec -T airflow-webserver airflow dags state industry_metrics_from_input $(date +%Y-%m-%d) | tail -n 1 | awk '{print $2}')
            echo "Current state: $state"
            if [ "$state" = "success" ]; then
              echo "✅ DAG succeeded"
              finished=true
              break
            fi
            sleep $interval
            elapsed=$((elapsed + interval))
          done
          if [ "$finished" = false ]; then
            echo "❌ DAG did not finish in time"
            docker-compose logs airflow-webserver
            exit 1
          fi

      # Pytest 実行（成果物確認）
      - name: Run pytest
        run: docker-compose exec -T airflow-webserver pytest /opt/airflow/tests

      # Tear down
      - name: Tear down
        if: always()
        run: docker-compose down -v
        
