name: e2e-test

on:
  push:
    branches:
      - main
  pull_request:

jobs:
  e2e-test:
    runs-on: ubuntu-latest

    steps:
      # 1. コードをチェックアウト
      - name: Checkout repository
        uses: actions/checkout@v3

      # 2. 依存パッケージをインストール
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-pip python3-venv

      # 3. Docker Compose Plugin をインストール (方法2)
      - name: Install Docker Compose plugin
        run: |
          sudo apt-get update
          sudo apt-get install -y ca-certificates curl gnupg lsb-release
          sudo mkdir -m 0755 -p /etc/apt/keyrings
          curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
          echo \
            "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
            $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
          sudo apt-get update
          sudo apt-get install -y docker-compose-plugin
          docker compose version

      # 4. Airflow を Docker Compose で起動
      - name: Start Airflow with Docker Compose
        run: docker compose up -d

      # 5. Airflow DB 初期化
      - name: Initialize Airflow DB
        run: docker compose exec -T airflow-scheduler airflow db init

      # 6. Webserver が立ち上がるのを待つ
      - name: Wait for Airflow webserver to be ready
        run: |
          for i in {1..10}; do
            if docker compose ps | grep "airflow-webserver" | grep "Up"; then
              echo "Webserver is running!"
              exit 0
            fi
            echo "⏳ Waiting for webserver... ($i/10)"
            sleep 15
          done
          echo "❌ Webserver did not start in time"
          exit 1

      # 7. DAG 実行トリガー
      - name: Trigger DAG run
        run: docker compose exec -T airflow-webserver airflow dags trigger industry_metrics_from_input

      # 8. pytest 実行（出力ファイル検証）
      - name: Run pytest (check output files)
        run: |
          pip install pytest pandas
          pytest tests/test_forecast.py -v

      # 9. AWS CLI インストール
      - name: Install AWS CLI
        run: |
          sudo apt-get update
          sudo apt-get install -y unzip
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip -q awscliv2.zip
          sudo ./aws/install
          aws --version

      # 10. アップロード確認 (S3)
      - name: Verify file uploaded to AWS S3
        run: |
          aws s3 ls s3://${{ secrets.AWS_BUCKET }}/metrics/ --recursive

      # 11. gcloud CLI インストール
      - name: Install gcloud CLI
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.GCP_PROJECT_ID }}
          service_account_key: ${{ secrets.GCP_SA_KEY }}
          export_default_credentials: true

      # 12. アップロード確認 (GCS)
      - name: Verify file uploaded to GCS
        run: |
          gsutil ls gs://${{ secrets.GCS_BUCKET }}/metrics/

      # 13. BigQuery にロードされたか確認
      - name: Verify data loaded into BigQuery
        run: |
          bq query --nouse_legacy_sql \
          'SELECT * FROM `${{ secrets.GCP_PROJECT_ID }}.${{ secrets.BQ_DATASET }}.retail_metrics` LIMIT 10'
