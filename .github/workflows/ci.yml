name: CI - Airflow PoC

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  e2e-test:
    runs-on: ubuntu-latest

    env:
      # AWS Ë™çË®ºÊÉÖÂ†±
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}

      # GCP Ë™çË®ºÊÉÖÂ†±
      GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/gcp-key.json
      GCP_PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
      BIGQUERY_DATASET: ${{ secrets.BIGQUERY_DATASET }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Write GCP credentials file
        run: |
          echo '${{ secrets.GCP_CREDENTIALS }}' > $GOOGLE_APPLICATION_CREDENTIALS

      - name: Set up Docker Compose
        run: |
          sudo apt-get update
          sudo apt-get install -y docker-compose google-cloud-cli awscli

      - name: Start Airflow with Docker Compose
        run: |
          docker-compose up -d
          echo "‚è≥ Waiting for Airflow services..."
          sleep 60

      - name: Initialize Airflow DB
        run: |
          docker exec mogiproject_airflow-webserver_1 airflow db init

      - name: Trigger DAG run
        run: |
          docker exec mogiproject_airflow-webserver_1 airflow dags trigger -d industry_metrics_from_input
          echo "‚è≥ Waiting for DAG execution..."
          sleep 120
          docker exec mogiproject_airflow-webserver_1 airflow dags state industry_metrics_from_input $(date +%Y-%m-%d)

      - name: Run pytest (check output files)
        run: |
          pip install pytest pandas
          pytest -v

      # ===== Â§ñÈÉ®„Çµ„Éº„Éì„ÇπËª¢ÈÄÅÁ¢∫Ë™ç =====

      - name: Verify file uploaded to AWS S3
        run: |
          echo "üì¶ Checking files in S3 bucket..."
          aws s3 ls s3://my-s3-bucket/metrics/

      - name: Verify file uploaded to GCS
        run: |
          echo "üì¶ Checking files in GCS bucket..."
          gcloud auth activate-service-account --key-file=$GOOGLE_APPLICATION_CREDENTIALS
          gsutil ls gs://my-gcs-bucket-2025-demo/metrics/

      - name: Verify data loaded into BigQuery
        run: |
          echo "üìä Checking tables in BigQuery dataset..."
          bq ls $BIGQUERY_DATASET
