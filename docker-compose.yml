version: "3"

services:
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  redis:
    image: redis:latest

  airflow-webserver:
    image: apache/airflow:2.7.2
    depends_on:
      - postgres
      - redis
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=1234567890abcdef1234567890abcdef
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=false
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      # GCP認証
      - GOOGLE_APPLICATION_CREDENTIALS=/opt/airflow/keys/gcp-key.json
      # AWS認証
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./keys:/opt/airflow/keys:ro
    ports:
      - "8080:8080"
    command: webserver

  airflow-scheduler:
    image: apache/airflow:2.7.2
    depends_on:
      - postgres
      - redis
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=1234567890abcdef1234567890abcdef
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=false
      - AIRFLOW__CORE__LOAD_EXAMPLES=false
      # GCP認証
      - GOOGLE_APPLICATION_CREDENTIALS=/opt/airflow/keys/gcp-key.json
      # AWS認証
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./keys:/opt/airflow/keys:ro
    command: scheduler

volumes:
  postgres-db-volume:
